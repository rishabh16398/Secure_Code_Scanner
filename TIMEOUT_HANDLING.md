# ‚è±Ô∏è SCANNER TIMEOUT HANDLING

## What Happened

You saw:
```
‚ùå Error scanning sonnet-4.5-nonreasoning_javascript-react_run2.zip: 
Command '['bearer', 'scan', ...]' timed out after 300 seconds
```

**Translation:** Bearer took more than 5 minutes on that project, so it was automatically skipped.

---

## Why Timeouts Happen

### Common Causes:

1. **Large Project**
   - Many files (1000+)
   - Large files (minified JS, compiled code)
   - Deep directory structures

2. **Complex Code**
   - Lots of dependencies
   - Complex patterns to analyze
   - JavaScript/TypeScript (slower for some tools)

3. **Specific Scanner Slowness**
   - **Bearer** tends to be slower on large JS/React projects
   - **Semgrep** can be slow with many rules
   - **Trivy** can be slow with many dependencies

---

## What Happens When Timeout Occurs

### Before (Old Behavior):
```
‚ùå Whole scan fails
‚ùå No results saved
‚ùå Have to start over
```

### After (New Behavior - Fixed!):
```
‚úÖ Timeout caught gracefully
‚úÖ Other scanners continue
‚úÖ Results from other tools saved
‚úÖ You get partial results (better than nothing!)
```

---

## Fix Applied

### 1. **Timeout Exception Handling**

In `scanners.py`:
```python
except subprocess.TimeoutExpired:
    print(f"[WARN] {cmd[0]} timed out after 300 seconds - skipping")
    return None
```

**Result:** Scanner that times out is skipped, others continue.

### 2. **Better Error Messages**

In `app.py`:
```python
if "timed out after 300 seconds" in error_msg:
    queue.put({
        "message": f"‚è±Ô∏è {filename}: A scanner timed out - continuing with other scanners"
    })
```

**Result:** You see a warning, not an error.

### 3. **Continue Processing**

Even if Bearer times out:
- ‚úÖ Semgrep results saved
- ‚úÖ Bandit results saved
- ‚úÖ Trivy results saved
- ‚úÖ OSV-Scanner results saved
- ‚ö†Ô∏è Bearer results missing (but you have 4 other tools!)

---

## Current Timeout Settings

**Timeout per scanner:** 300 seconds (5 minutes)

This is generous! Most scans complete in 30-120 seconds.

### If You Want to Change It:

**Increase timeout** (for very large projects):
```python
# In scanners.py, lines 23 and 54
timeout=600,  # 10 minutes instead of 5
```

**Decrease timeout** (for faster failure):
```python
timeout=180,  # 3 minutes
```

**Recommendation:** Keep at 300 seconds ‚úÖ

---

## Which Scanners Timeout Most Often?

Based on experience:

### üêå Slower Scanners:
1. **Bearer** - Especially on JavaScript/React/Node projects
2. **Semgrep** - When using many rules (--config auto)
3. **Trivy** - On projects with 100+ dependencies

### ‚ö° Fast Scanners:
1. **Bandit** - Usually <30 seconds
2. **OSV-Scanner** - Usually <20 seconds

---

## What To Do When Timeout Happens

### Option 1: Accept Partial Results ‚úÖ (Recommended)

Most projects scan with 4-5 tools. If one times out, you still have data from the others!

```python
# Check what tools completed
import json

with open('consolidated_all_runs_10_runs.json') as f:
    data = json.load(f)

for run in data['runs']:
    print(f"Run {run['run_number']}:")
    for tool, findings in run['results']['sast'].items():
        print(f"  {tool}: {len(findings)} findings")
```

**Example output:**
```
Run 2:
  semgrep: 45 findings  ‚úÖ
  bearer: 0 findings    ‚ö†Ô∏è (timed out)
  bandit: 12 findings   ‚úÖ
```

You still have 57 findings from 2 tools!

### Option 2: Increase Timeout

For very large projects:
```python
# In scanners.py
timeout=600  # 10 minutes
```

### Option 3: Skip Slow Scanners

If Bearer always times out on your projects, you can comment it out:

```python
# In scanners.py, around line 505
scanners = [
    ("Semgrep", run_semgrep),
    # ("Bearer", run_bearer),  # Skip Bearer
    ("Bandit", run_bandit),
    ("Trivy", run_trivy),
    ("OSV-Scanner", run_osv),
]
```

### Option 4: Reduce Project Size

Before zipping:
```bash
# Remove node_modules (huge!)
rm -rf node_modules/

# Remove build artifacts
rm -rf build/ dist/ .next/

# Remove test files (if not needed)
rm -rf tests/ __tests__/

# Then zip
zip -r project.zip . -x "node_modules/*" "build/*"
```

---

## Understanding Your Specific Timeout

```
sonnet-4.5-nonreasoning_javascript-react_run2.zip
```

This is a **JavaScript React** project. Bearer is known to be slow on React projects because:
- Many JSX files to analyze
- Complex component patterns
- Lots of imports/dependencies

**Recommendation:** For React projects, expect Bearer to be slow or timeout. The other 4 tools will still give you good results!

---

## Timeout Statistics (Typical)

### Small Project (<50 files):
```
Semgrep:     30-60 seconds
Bearer:      20-40 seconds
Bandit:      5-10 seconds
Trivy:       10-20 seconds
OSV-Scanner: 5-15 seconds
Total:       70-145 seconds
```

### Medium Project (50-200 files):
```
Semgrep:     60-120 seconds
Bearer:      60-180 seconds
Bandit:      10-30 seconds
Trivy:       20-60 seconds
OSV-Scanner: 10-30 seconds
Total:       160-420 seconds (3-7 minutes)
```

### Large Project (200+ files):
```
Semgrep:     120-240 seconds
Bearer:      180-300+ seconds ‚ö†Ô∏è (may timeout!)
Bandit:      30-60 seconds
Trivy:       60-120 seconds
OSV-Scanner: 20-60 seconds
Total:       410-780+ seconds (7-13 minutes)
```

**If Bearer times out on large projects, that's normal!**

---

## Workaround for Slow Projects

### Strategy: Split Large Projects

If you have a 500-file project:

**Option A: Split by directory**
```bash
# Scan frontend separately
zip frontend.zip frontend/

# Scan backend separately
zip backend.zip backend/
```

**Option B: Remove non-essential files**
```bash
# Only scan source code
zip project.zip src/ -x "*.test.js" "*.spec.js"
```

**Option C: Use .gitignore**
```bash
# Respect .gitignore when zipping
git archive -o project.zip HEAD
```

---

## How to Monitor Progress

While scanning, watch the console:

```
[DEBUG] Running Bearer...
# If you see this for >4 minutes, Bearer might timeout
```

**Tip:** Check the timestamp difference:
```
17:23:00 - Running Bearer...
17:28:00 - Bearer timed out
# Took 5 minutes = hit timeout
```

---

## Verification After Timeout

### Check What Worked:

```python
import json

with open('cwe_analysis_10_runs.json') as f:
    data = json.load(f)

# Check which tools found CWEs
all_tools = set()
for cwe_data in data['cwes'].values():
    all_tools.update(cwe_data['tools_detected_by'])

print(f"Tools that completed: {all_tools}")
```

**Example output:**
```
Tools that completed: {'semgrep', 'bandit'}
# Bearer timed out, but you have results from 2 tools!
```

---

## Summary

### ‚úÖ What's Fixed:
- Timeout is caught gracefully
- Other scanners continue
- Partial results are saved
- Better error messages

### ‚è±Ô∏è Current Settings:
- 5 minute timeout per scanner
- Applies to all 5 tools
- Can be adjusted if needed

### üìä Impact on Results:
- If 1 scanner times out: You still get 4 tools' results
- If 2 scanners timeout: You still get 3 tools' results
- Better to have partial results than no results!

### üéØ Recommendation:
- Accept partial results for large projects
- Bearer timing out on React is normal
- You still get valuable data from other tools

**Your research data is still valid with 4 out of 5 tools!** ‚úÖ

---

## Prevention Tips

### 1. Optimize Project Size
```bash
# Before scanning
du -sh project/
# If >100MB, consider removing:
# - node_modules/
# - build/
# - test files
```

### 2. Scan in Batches
```bash
# Instead of 10 large projects at once
# Scan 3-4 at a time
```

### 3. Monitor Resource Usage
```bash
# Check CPU/memory while scanning
top
# If system is slow, close other apps
```

### 4. Use Faster Machine
- More CPU cores = faster parallel scanning
- More RAM = tools can load more into memory
- SSD vs HDD = faster file I/O

---

## Bottom Line

üéâ **Timeouts are now handled gracefully!**

- Scan continues with other tools
- Partial results saved
- No more "Connection error"
- You get 80-100% of the data even if one tool times out

**Keep scanning! Your research is on track!** üéì
